# Анализ

Основная цель, которую будем преследовать с внедрением логирования - сформировать представление о состоянии заказа в разных частях системы в контексте пользователя, инициировавшего данное изменение. Кроме того, будем фиксировать серьезные нарушения в работе системы, например, сообщать о недоступности БД, об ошибках выхода по таймауту, о невозможности опубликовать или принять сообщения из RabbitMQ.

В INFO будем логировать:

- Создание нового заказа. Логируем время, идентификатор покупателя, идентификатор заказа.
- Изменение статуса заказа в Shop API, CRM API, MES API. Логируем время, идентификатор пользователя (покупателя, продавца, оператора), идентификатор заказа, новое состояние.
- Загрузка 3D-модели в S3-хранилище. Логируем время, идентификатор пользователя, имя файла.
- Начало и завершение расчетов стоимости по 3D-модели. Логируем время, имя файла.

# Мотивация

Наличие логов поможет отладить проблемные компоненты системы и зафиксировать ключевые точки эволюции состояния элементов (сущностей) системы.
В случае сбоя можно зафиксировать детальное описание ошибки, контекста операции и локального окружения, которые могли привести к нарушению работы системы.
Также логирование хорошо сочетается с мониторингом. Внедрение обоих подходов позволяет сформировать более полную картину происходящего в системе, каждый из подходов будет компенсировать ограничения другого.

Если ресурсов команды не будет хватать реализовать логирование и трейсинг во всех API системы одновременно, то имеет смысл сконцентрироваться на внедрении этих инструментов в первую очередь в систему MES API, в которой заказы проходят цикл производства и отправки готовой продукции клиентам. После покупки и "прикручивания" MES (чужого софта) в общую инфрастуктуру, могли появиться ошибки. Повышение наблюдаемости этой части системы может дать ценную информацию о причинах наблюдаемых проблем.

# Предлагаемое решение

Решение будем реализовывать на стеке ELK: Elasticsearch, Logstash и Kibana. Для сбора логов воспользуемся Filebeat.

[Доработанная диаграмма С4](./jewerly_c4_model.drawio)

Политика безопасности:

- чувствительные данные можно изменять во время передачи в индекс, например, задать специальные правила конвертации в настройках Logstash (например, закрывать часть информации звездочками ('*'))
- доступ до логов нужно иметь в первую очередь разработчикам. Для обеспечения безопасности потребуется:
    - защитить подключение к СУБД, настроив аутентификацию
    - настроить TLS/SSL для защищенного взаимодействия между серверами
В бесплатной версии Elasticsearch с безопасностью все плохо, поэтому, чтобы оставаться на бесплатных opensource решениях, можно заменить "главный" компонент (Elasticsearch) на аналог: OpenSearch.

Политика хранения в отношении логов:

- Хранить логи с информаций о статусе заказа желательно так, чтобы по ним можно было проследить весь жизненный цикл заказа (от создания от завершения). Так как изготовление может вестись несколько недель, но бывали случаи с месячными задержками, то имеет смысл хранить логи месяца 3.
- Если логов получается слишком много, можно попробовать разделить их на разные категории с разным временем хранения.

## Мероприятия для превращения системы сбора логов в систему анализа логов

Можно подключить модули предупреждений к Elasticsearch или Opensearch. Интерес могут представлять:
- Высокая частота ошибок в логах.
- Аномально высокое количество записей о создании заказов за секунду.
- Аномально высокое количество записей о расчетах стоимости 3D-моделей.